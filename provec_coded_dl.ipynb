{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b77f1fc-5c6d-4ead-a205-d53957ae87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5b9707-9e1f-4044-b337-5c0faa759632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence  delta_log10Ka\n",
      "0  NITNLCPFGEVFNATRFASVYCWNRKRISNCVADYSVLYNSASFST...          -2.05\n",
      "1  NITNLCPFGEVFFATRFASVYAWNRKRISNCVADYSVLYNSASFST...          -0.42\n",
      "2  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...          -4.76\n",
      "3  NITNLCPFGEVFNATRFVSVYAWNRKRISNCVADYSVLYNSASFST...          -0.61\n",
      "4  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...          -1.15\n"
     ]
    }
   ],
   "source": [
    "# Load the genotype_fitness_data.tsv file\n",
    "file_path = 'C:/Users/Thomascrx/Desktop/ml_code/sequence_points_file.csv'  # Replace with your file path\n",
    "genotype_fitness_data = pd.read_csv(file_path)\n",
    "print(genotype_fitness_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae44383-632a-42e1-8aee-899e12f70229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (136204, 199, 100)\n"
     ]
    }
   ],
   "source": [
    "def cut_to_provec(sequence, num):\n",
    "    def split_overlapping(s, window_size):\n",
    "        return [s[i:i + window_size] for i in range(len(s) - window_size + 1)]\n",
    "    return [split_overlapping(i, window_size=num) for i in sequence]\n",
    "\n",
    "sequence = genotype_fitness_data[\"sequence\"]\n",
    "sequence = cut_to_provec(sequence, 3)\n",
    "provec = pd.read_csv(\"C:/Users/Thomascrx/Desktop/protVec_100d_3grams.csv\", sep=\"\\t\")\n",
    "\n",
    "columns = list(provec.columns)\n",
    "columns.pop(0)\n",
    "columns_to_merge = columns\n",
    "provec['Merged'] = provec[columns_to_merge].apply(lambda row: row.tolist(), axis=1)\n",
    "provec.drop(columns=columns_to_merge, inplace=True)\n",
    "provec_dict = provec.set_index('words')['Merged'].to_dict()\n",
    "\n",
    "def provec_encode_aa(sequence):\n",
    "    return np.array([provec_dict[aa] for aa in sequence])\n",
    "\n",
    "X = np.array([provec_encode_aa(aa) for aa in sequence])\n",
    "y = genotype_fitness_data['delta_log10Ka'].values\n",
    "print(f\"X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41ed752-4a2a-4f24-8019-de0fb4fd3156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64091236, -0.73472378,  0.38318452, ..., -0.23630753,\n",
       "         0.85832559, -1.05736203],\n",
       "       [ 1.29960596, -1.84373196, -0.02712866, ..., -1.21963456,\n",
       "        -2.42604606, -1.81729888],\n",
       "       [ 2.72284051,  1.74630444, -0.36018767, ..., -0.05598329,\n",
       "        -1.71761786, -2.15516764],\n",
       "       ...,\n",
       "       [ 0.90332009,  1.12095939,  0.27667378, ..., -2.50335607,\n",
       "         2.02559375, -0.71210782],\n",
       "       [ 0.03582682,  0.00756962,  0.38211474, ..., -1.07164549,\n",
       "         1.6623494 ,  0.39921289],\n",
       "       [ 1.00999226,  0.60483684, -2.00419012, ..., -0.56204786,\n",
       "         0.67772929,  1.52278413]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize X\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c109541-57da-4ec2-9947-1a0930ed855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.04974056, -1.14949301,  0.95346075,  0.6798234 , -1.14949301,\n",
       "        0.15281811, -1.14949301,  0.88758509,  1.21696339, -1.14949301,\n",
       "        0.79637264, -1.14949301,  0.18828962,  1.26256962,  0.95346075,\n",
       "        0.10721189, -1.14949301, -0.32858094,  0.25416528,  1.23723283,\n",
       "       -0.01440472,  0.37071453,  1.16122245,  0.54807208,  1.22709811,\n",
       "       -1.14949301, -1.14949301,  1.24736754,  0.75076641,  0.39605132,\n",
       "        1.20176132,  0.92812396,  0.78623792,  0.02106679, -0.07014566,\n",
       "        0.51766792,  1.24230019, -1.14949301,  0.96866283,  1.29297377,\n",
       "        0.2643    ,  1.24230019, -1.14949301, -1.14949301,  1.21189604,\n",
       "        0.15281811,  0.28456943,  0.49233113,  1.26256962,  0.62408245,\n",
       "       -1.14949301, -1.14949301,  0.81157472, -1.14949301,  1.26763698,\n",
       "        0.34537774, -0.63262245,  1.26256962,  0.01599944,  0.77610321,\n",
       "        0.76596849, -1.14949301, -1.14949301,  1.04467321, -1.14949301,\n",
       "        0.29977151,  1.15108773,  0.52273528, -0.55661207,  0.0565383 ,\n",
       "        0.75076641, -1.14949301,  1.21189604, -1.14949301, -1.14949301,\n",
       "        0.22376113,  0.1426834 ,  0.8622483 , -1.14949301, -0.7846432 ,\n",
       "        0.52273528,  1.11054887, -1.14949301, -1.01774169, -1.14949301,\n",
       "        1.23723283,  1.09534679, -1.14949301, -1.14949301, -1.14949301,\n",
       "        1.04974056,  1.14095302, -1.14949301, -1.14949301,  0.13761604,\n",
       "        1.18655924, -1.14949301, -1.14949301, -1.14949301])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize y\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "y = (y - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa95e9e-a16c-48e2-8db8-7d9162b720d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存变量\n",
    "# dump([X,y], 'variables.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf30ca8-15ff-44c6-abcf-b950c7e59e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([108963, 199, 100])\n",
      "y_train_tensor shape after view: torch.Size([108963, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "print(f\"y_train_tensor shape after view: {y_train_tensor.shape}\")\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c517373-8a14-4c75-aee2-1ff632482daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Avg Loss: 1.1648\n",
      "Epoch 1, Avg Loss: 0.9974\n",
      "Epoch 2, Avg Loss: 0.9971\n",
      "Epoch 3, Avg Loss: 0.9971\n",
      "Epoch 4, Avg Loss: 0.9971\n",
      "Epoch 5, Avg Loss: 0.9970\n",
      "Epoch 6, Avg Loss: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fce4177de40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/logging/__init__.py\", line 243, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 5506, 5508) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     55\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 57\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 5506, 5508) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    seq_len = 199          # 序列长度\n",
    "    vocab_size = 100       # 新的编码维度\n",
    "    d_model = 512         # 嵌入维度\n",
    "    nhead = 8             # 注意力头数\n",
    "    num_layers = 6       # 编码器层数\n",
    "    dim_feedforward = 1024 # 前馈网络维度\n",
    "    dropout = 0.1         # Dropout 比率\n",
    "    batch_size = 32       # Batch Size（根据 GPU 显存调整）\n",
    "    lr = 0.005           # 学习率\n",
    "    weight_decay = 0.01   # 权重衰减\n",
    "    epochs = 100          # 训练轮数\n",
    "    grad_clip = 5.0       # 梯度裁剪阈值\n",
    "    log_dir = \"runs/exp1\" # TensorBoard 日志目录\n",
    "\n",
    "class ProteinTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(config.vocab_size, config.d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.d_model,\n",
    "            nhead=config.nhead,\n",
    "            dim_feedforward=config.dim_feedforward,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True  # Set batch_first to True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.num_layers)\n",
    "        self.fc = nn.Linear(config.seq_len * config.d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)          # (batch, 199, 100) → (batch, 199, 256)\n",
    "        x = self.encoder(x)            # (batch, 199, 256)\n",
    "        x = x.reshape(x.size(0), -1)   # (batch, 199 * 256=50944)\n",
    "        return self.fc(x)              # (batch, 1)\n",
    "\n",
    "config = Config()\n",
    "model = ProteinTransformer(config)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "criterion = nn.MSELoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "writer = SummaryWriter(log_dir=config.log_dir)\n",
    "\n",
    "dataset = TensorDataset(torch.randn(136204, 199, 100), torch.randn(136204, 1))\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (batch_X, batch_y) in enumerate(dataloader):\n",
    "        batch_X, batch_y = batch_X.to(\"cuda\"), batch_y.to(\"cuda\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        current_step = epoch * len(dataloader) + batch_idx\n",
    "        if batch_idx % 10 == 0:\n",
    "            writer.add_scalar(\"Loss/train (batch)\", loss.item(), current_step)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    writer.add_scalar(\"Loss/train (epoch)\", avg_loss, epoch)\n",
    "    print(f\"Epoch {epoch}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
